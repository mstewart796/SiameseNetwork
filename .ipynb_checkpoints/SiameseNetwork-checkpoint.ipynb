{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "aVvzlmAbGUEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import resnet18"
      ],
      "metadata": {
        "id": "Pws05IJ8GZHR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Siamese Network Class"
      ],
      "metadata": {
        "id": "qyae8CDXGbQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, pretrained_model):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        # Load the pretrained model\n",
        "        self.pretrained_model = pretrained_model\n",
        "        # Replace the last fully connected layer with an identity layer\n",
        "        self.pretrained_model.fc = nn.Identity()\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        # Forward pass through the pretrained model\n",
        "        output = self.pretrained_model(x)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Forward pass for both inputs through the pretrained model\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "zzh-7tHgGd4g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the model and network"
      ],
      "metadata": {
        "id": "cCmLiWtwGqsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained ResNet18 model\n",
        "pretrained_resnet = models.resnet18(weights='DEFAULT')\n",
        "# Create the Siamese network instance\n",
        "siamese_net = SiameseNetwork(pretrained_model=pretrained_resnet)"
      ],
      "metadata": {
        "id": "7FsDzx4pGwo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f67513df-a8cf-4d26-e695-b1ff00bc8409"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 95.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set dataset path"
      ],
      "metadata": {
        "id": "Tb6ZdMywHTDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/SiameseNetwork/post-processed-celebs'\n"
      ],
      "metadata": {
        "id": "Hh4bGTskHasW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Custom Dataset class"
      ],
      "metadata": {
        "id": "KJC5t2AWHgUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(ImageFolder):\n",
        "    def __init__(self, root, transform=None):\n",
        "        super(CustomDataset, self).__init__(root, transform=transform)\n",
        "\n",
        "    # Method to retrieve items from the dataset given an index\n",
        "    def __getitem__(self, index):\n",
        "        # Retrieve the path for the image at the specified index\n",
        "        image_path, _ = self.samples[index]\n",
        "        image = Image.open(image_path)\n",
        "        # Apply transformations to the image if transform is specified\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, image_path\n",
        "\n",
        "dataset = CustomDataset(dataset_path, transform=ToTensor())\n",
        "batch_size = 64\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "sLvmFhQiHiXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform inference"
      ],
      "metadata": {
        "id": "891gE-esHqIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "siamese_net.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "siamese_net.eval()\n",
        "\n",
        "# Initialize lists to store descriptor vectors and file paths\n",
        "descriptor_vectors = []\n",
        "file_paths = []\n",
        "\n",
        "# Iterate through batches in the data loader\n",
        "for batch in data_loader:\n",
        "    images, paths = batch\n",
        "    images = images.to(device)\n",
        "    with torch.no_grad():\n",
        "        # Forward pass through the Siamese network with image pairs\n",
        "        outputs = siamese_net(images, images)\n",
        "    descriptor_vectors.extend(outputs[0].cpu().numpy())\n",
        "    file_paths.extend(paths)"
      ],
      "metadata": {
        "id": "bmQSvoJ7Hs50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge file path and descriptor vector"
      ],
      "metadata": {
        "id": "5t_kgnab1n4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "descriptor_vectors_with_paths = list(zip(descriptor_vectors, file_paths))"
      ],
      "metadata": {
        "id": "KwkntN401qlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up database and create table"
      ],
      "metadata": {
        "id": "ypQxnYDBIB8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect('/content/drive/MyDrive/SiameseNetwork/full_database.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create a table to store image paths and descriptor vectors\n",
        "cursor.execute('''CREATE TABLE IF NOT EXISTS ImageDescriptors\n",
        "                  (id INTEGER PRIMARY KEY,\n",
        "                   file_path TEXT,\n",
        "                   descriptor_vector BLOB)''')"
      ],
      "metadata": {
        "id": "KnMVuZizIaj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Insert images and descriptor vectors"
      ],
      "metadata": {
        "id": "KArdwP4fIdZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert data into the table\n",
        "for descriptor, file_path in descriptor_vectors_with_paths:\n",
        "    cursor.execute(\"INSERT INTO ImageDescriptors (file_path, descriptor_vector) VALUES (?, ?)\", (file_path, descriptor.tobytes()))\n",
        "\n",
        "# Commit changes and close the connection\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"Database created and populated.\")"
      ],
      "metadata": {
        "id": "2tt8-AfOIiPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add image of me without a mask\n"
      ],
      "metadata": {
        "id": "ypmfLK_bIuH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "image_path = '/content/drive/MyDrive/SiameseNetwork/withoutMask.jpg'\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.title(f'Me without a mask:')\n",
        "plt.axis('off')  # Turn off axis labels and ticks\n",
        "plt.show()\n",
        "\n",
        "# Convert the image to a tensor\n",
        "transform = transforms.ToTensor()\n",
        "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Move the image tensor to the appropriate device (CPU/GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "image_tensor = image_tensor.to(device)\n",
        "\n",
        "# Pass the image tensor through your Siamese network to get the descriptor vector\n",
        "with torch.no_grad():\n",
        "    descriptor_vector = siamese_net.forward_once(image_tensor)\n",
        "\n",
        "# Convert the descriptor vector to bytes\n",
        "descriptor_bytes = descriptor_vector.cpu().numpy().tobytes()\n",
        "\n",
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect('/content/drive/MyDrive/SiameseNetwork/full_database.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Insert the image path and descriptor vector into the database\n",
        "cursor.execute(\"INSERT INTO ImageDescriptors (file_path, descriptor_vector) VALUES (?, ?)\", (image_path, descriptor_bytes))\n",
        "\n",
        "# Commit changes and close the connection\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"Image added to the database with its descriptor vector.\")\n"
      ],
      "metadata": {
        "id": "YD6VTQ7OIwwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verify image"
      ],
      "metadata": {
        "id": "AbrH7HW6I4QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new image\n",
        "query_image_path = '/content/drive/MyDrive/SiameseNetwork/withMask.jpg'\n",
        "query_image = Image.open(query_image_path)\n",
        "\n",
        "# Display the query image\n",
        "plt.imshow(query_image)\n",
        "plt.axis('off')\n",
        "plt.title(\"Query Image\")\n",
        "plt.show()\n",
        "\n",
        "# Convert the query image to a tensor\n",
        "transform = transforms.ToTensor()\n",
        "query_image_tensor = transform(query_image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Move the query image tensor to the appropriate device (CPU/GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "query_image_tensor = query_image_tensor.to(device)\n",
        "\n",
        "# Pass the query image tensor through your Siamese network to get its descriptor vector\n",
        "with torch.no_grad():\n",
        "    query_descriptor_vector = siamese_net.forward_once(query_image_tensor)\n",
        "\n",
        "# Convert the query descriptor vector to numpy array for similarity calculation\n",
        "query_descriptor_np = query_descriptor_vector.cpu().numpy()\n",
        "\n",
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect('/content/drive/MyDrive/SiameseNetwork/full_database.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Retrieve all descriptor vectors from the database\n",
        "cursor.execute(\"SELECT file_path, descriptor_vector FROM ImageDescriptors\")\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "# Calculate cosine similarity with each descriptor vector in the database\n",
        "similar_images = []\n",
        "for row in rows:\n",
        "    file_path, descriptor_bytes = row\n",
        "    descriptor_np = np.frombuffer(descriptor_bytes, dtype=np.float32)\n",
        "    descriptor_np = descriptor_np.reshape((1, -1))  # Reshape to match the query descriptor shape\n",
        "    similarity = cosine_similarity(query_descriptor_np, descriptor_np)\n",
        "    similar_images.append((file_path, similarity[0][0]))\n",
        "\n",
        "# Sort similar images by similarity score (descending order)\n",
        "similar_images.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display only the most similar image\n",
        "if similar_images:\n",
        "    top_image_path = similar_images[0][0]\n",
        "    top_similarity = similar_images[0][1]\n",
        "    top_image = Image.open(top_image_path)\n",
        "    plt.imshow(top_image)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Most Similar Image (Similarity: {top_similarity:.4f})\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No similar images found.\")\n",
        "\n",
        "# Close the connection\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "2F292XsfJFg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}